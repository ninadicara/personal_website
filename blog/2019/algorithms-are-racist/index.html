<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Nina  Di Cara


  | Yes, algorithms are racist (because we are)

</title>
<meta name="description" content="Website and projects
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.xyz/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸŒ»</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/blog/2019/algorithms-are-racist/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Nina</span>   Di Cara
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item active">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/code/">
                code
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Yes, algorithms are racist (because we are)</h1>
    <p class="post-meta">February 24, 2019</p>
  </header>

  <article class="post-content">
    <p>A journalist tweeted this week that Alexandria Ocasio-Cortez (AOC) said that algorithms, driven by math, are racist. Something about the way the tweet was written struck me as sceptical, and many people in tech seemed to feel the same way. A lot of tech-experienced people weighed in to defend AOC, because if you have an understanding of how algorithms are made, and the existence of systemic racism, then youâ€™ll understand that sheâ€™s right.</p>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Socialist Rep. Alexandria Ocasio-Cortez (D-NY) claims that algorithms, which are driven by math, are racist <a href="https://t.co/X2veVvAU1H">pic.twitter.com/X2veVvAU1H</a></p>&mdash; Ryan Saavedra (@RealSaavedra) <a href="https://twitter.com/RealSaavedra/status/1087627739861897216?ref_src=twsrc%5Etfw">January 22, 2019</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>Now, before we go into the algorithm part lets talk a little about institutional racism. We know that racism is very present in the criminal justice system, with people who are Black, or people of colour (POC), far more likely to be arrested than White people (over 3 times more likely). If you find that hard to swallow please note that itâ€™s information displayed openly on the <a href="https://www.ethnicity-facts-figures.service.gov.uk/crime-justice-and-the-law/policing/number-of-arrests/latest">.gov.uk website</a>.</p>

<p>This is the result of racism in our society that plays out in a million microscopic ways every day. Wages, funding decisions, educational opportunities, access to pro-social activities, proximity to crime, who gets the best medical treatment and more, which disadvantages people who are black or from an ethic minority on an institutional scale.</p>

<p>Imagineâ€¦
if we were to create an algorithm that created a â€˜risk scoreâ€™ for people who were likely to get into crime, and use it to target interventions towards those who might need it. We need to give the computer a lot of information for it to decide what risk level to give each new person it will classify. The data might include criminal justice information (criminal history, arrests), age, location, ethnicity and more.</p>

<p>(Iâ€™m sure you can see where this is going.)</p>

<p>If we fed the algorithm the arrest data we have the algorithm will learn from it. What the algorithms will learn is that Black people are three times more likely to be arrested than White people. As a result, the algorithm will be more likely to classify Black people with a higher risk score than White people, just based on their ethnicity.</p>

<p>This doesnâ€™t just work with race. If you happen to live in an area where there is a lot of violence, you may be assigned a higher risk score because all the algorithm can do is see a pattern and fit you into it. You live in a neighbourhood with a lot of crimeâ€¦ you are more likely to be involved in a crime.</p>

<p>By the way does this all sound like a completely unethical, terrifyingly dystopian experiment?</p>

<p><a href="https://link.springer.com/article/10.1007%2Fs11292-016-9272-0">Because it actually happened.</a></p>

<p>You can see how everything about social inequality is amplified and reinforced by giving the algorithm data that teaches it bias, racism and prejudice.</p>

<p>While the example above is about over-representation of Black people in the criminal justice system, there is also a huge problem with under-representation elsewhere. <a href="https://www.nature.com/articles/d41586-018-05707-8#ref-CR6">An article in Nature in July 2018</a> discusses this issue very well, and gives the example that an algorithm recognises a white woman in a white wedding dress as a â€˜Brideâ€™ but, not a Indian woman dressed in a traditional colourful wedding sari.</p>

<p>This is because the â€˜training dataâ€™ (the information the algorithm builds the patterns from) did not contain enough (or any) images of Indian brides to learn that they were brides too.</p>

<p>We get into more concerning territory when it comes to medical training data â€“ another example from the Nature article shows that an algorithm was much less accurate at detecting skin cancer in dark-skinned people that it was in White people, because less than 5% of the original data was from POC.</p>

<p>I would wager that if you are Black or a person of colour you will not be surprised by this post. This information is unfortunately another extension of the same inequality that exists in day-to-day life. The people who are responsible for creating algorithms are usually White, male and highly-educated and largely unaware of their own societal privilege, working with lots of other people who look just like them, and who do not always notice the lack of diversity in their data either.</p>

<p>So there are three solutions that I can see. We need more diversity in computer science/maths, both ethnicity and gender-wise. Thereâ€™s a huge movement for it which is great, but itâ€™s never going to happen as fast as we want it to. Secondly, we need those who are currently responsible for creating these algorithms to take representation in training data seriously, and consider the real life applications of these algorithms in society. Lastly, companies who produce training data sets need to take responsibility for this too and acknowledge that they need to be sourcing more diverse information.</p>

<p>The thing is, if we got it right then maths could be helping us create the world we want to live in, rather than maintaining systems of white supremacy.</p>


  </article>

  

</div>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container">
    &copy; Copyright 2021 Nina  Di Cara.
    
    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
